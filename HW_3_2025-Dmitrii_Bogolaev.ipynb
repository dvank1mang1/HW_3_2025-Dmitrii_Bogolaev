{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7fcb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'lightgbm', '--quiet'])\n",
    "    import lightgbm as lgb\n",
    "\n",
    "pd.options.display.max_columns = 120\n",
    "SEED = 2025\n",
    "\n",
    "\n",
    "def seed_everything(seed: int = SEED) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "DATA_DIR = Path('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fd1f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (35344, 11)\n",
      "Test shape: (1404, 5)\n",
      "Store shape: (1208, 29)\n",
      "Sample submission shape: (1200, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test = pd.read_csv(DATA_DIR / 'test.csv')\n",
    "store = pd.read_csv(DATA_DIR / 'STORE_LOCATION.csv', sep=';')\n",
    "sample_submission = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "print('Store shape:', store.shape)\n",
    "print('Sample submission shape:', sample_submission.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79d03bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out.columns = [c.lower() for c in out.columns]\n",
    "    if 'unnamed: 0' in out.columns:\n",
    "        out = out.rename(columns={'unnamed: 0': 'id'})\n",
    "    return out\n",
    "\n",
    "\n",
    "def prepare_store_metadata(raw_store: pd.DataFrame) -> pd.DataFrame:\n",
    "    store_df = normalize_columns(raw_store)\n",
    "    time_cols = [c for c in store_df.columns if c.endswith('_dttm')]\n",
    "    for col in time_cols:\n",
    "        store_df[col] = pd.to_datetime(store_df[col], format='%d%b%Y:%H:%M:%S', errors='coerce')\n",
    "        store_df[f'{col}_year'] = store_df[col].dt.year\n",
    "        store_df[f'{col}_month'] = store_df[col].dt.month\n",
    "        store_df[f'{col}_isnull'] = store_df[col].isna().astype(np.int8)\n",
    "    store_df = store_df.drop(columns=time_cols)\n",
    "\n",
    "    hash_cols = [c for c in store_df.columns if 'hashing' in c]\n",
    "    for col in hash_cols:\n",
    "        store_df[col] = pd.factorize(store_df[col], sort=True)[0].astype('int32')\n",
    "    return store_df\n",
    "\n",
    "\n",
    "def add_group_lags(df: pd.DataFrame, group_cols: List[str], target_col: str, lags: List[int]) -> pd.DataFrame:\n",
    "    for lag in lags:\n",
    "        df[f'{target_col}_lag_{lag}'] = df.groupby(group_cols)[target_col].shift(lag)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_group_rolls(df: pd.DataFrame, group_cols: List[str], target_col: str, windows: List[int]) -> pd.DataFrame:\n",
    "    for window in windows:\n",
    "        df[f'{target_col}_roll_mean_{window}'] = (\n",
    "            df.groupby(group_cols, group_keys=False)[target_col]\n",
    "            .apply(lambda s: s.shift(1).rolling(window).mean())\n",
    "        )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3ffe2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xn/wr0tf689795drd8qrm11k1jm0000gn/T/ipykernel_91379/2503345812.py:10: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  full['period_start_dt'] = pd.to_datetime(full['period_start_dt'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (36748, 75)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df = normalize_columns(train)\n",
    "test_df = normalize_columns(test)\n",
    "store_meta = prepare_store_metadata(store)\n",
    "\n",
    "train_df['dataset'] = 'train'\n",
    "test_df['dataset'] = 'test'\n",
    "test_df['demand'] = np.nan\n",
    "\n",
    "full = pd.concat([train_df, test_df], ignore_index=True, sort=False)\n",
    "full['period_start_dt'] = pd.to_datetime(full['period_start_dt'], dayfirst=True, errors='coerce')\n",
    "full = full.merge(store_meta, how='left', on='store_location_rk')\n",
    "\n",
    "promo_cols = [c for c in ['promo1_flag', 'promo2_flag', 'autorization_flag'] if c in full.columns]\n",
    "for col in promo_cols:\n",
    "    full[col] = full[col].fillna(0)\n",
    "\n",
    "full['num_consultant'] = full['num_consultant'].fillna(0)\n",
    "\n",
    "full['price_regular'] = full.groupby('product_rk')['price_regular'].transform(lambda s: s.fillna(s.median()))\n",
    "full['price_after_disc'] = full['price_after_disc'].fillna(full['price_regular'])\n",
    "full['discount_amount'] = full['price_regular'] - full['price_after_disc']\n",
    "full['discount_pct'] = (full['discount_amount'] / full['price_regular'].replace(0, np.nan)).fillna(0)\n",
    "full['price_ratio'] = (full['price_after_disc'] / full['price_regular'].replace(0, np.nan)).fillna(1)\n",
    "\n",
    "\n",
    "iso_calendar = full['period_start_dt'].dt.isocalendar()\n",
    "full['weekofyear'] = iso_calendar.week.astype('Int16')\n",
    "full['weekofyear'] = full['weekofyear'].fillna(-1).astype(int)\n",
    "full['weekofyear'] = full['weekofyear'].replace(-1, np.nan)\n",
    "full['month'] = full['period_start_dt'].dt.month\n",
    "full['quarter'] = full['period_start_dt'].dt.quarter\n",
    "full['dayofweek'] = full['period_start_dt'].dt.weekday\n",
    "full['weekofmonth'] = (full['period_start_dt'].dt.day//7)\n",
    "full['is_month_start'] = full['period_start_dt'].dt.is_month_start.fillna(False).astype(int)\n",
    "full['is_month_end'] = full['period_start_dt'].dt.is_month_end.fillna(False).astype(int)\n",
    "full['dayofyear'] = full['period_start_dt'].dt.dayofyear\n",
    "\n",
    "train_mask = full['dataset'] == 'train'\n",
    "store_mean = full.loc[train_mask].groupby('store_location_rk')['demand'].mean()\n",
    "product_mean = full.loc[train_mask].groupby('product_rk')['demand'].mean()\n",
    "combo_mean = full.loc[train_mask].groupby(['product_rk', 'store_location_rk'])['demand'].mean()\n",
    "full['store_mean_demand'] = full['store_location_rk'].map(store_mean)\n",
    "full['product_mean_demand'] = full['product_rk'].map(product_mean)\n",
    "full['product_store_mean_demand'] = list(zip(full['product_rk'], full['store_location_rk']))\n",
    "full['product_store_mean_demand'] = full['product_store_mean_demand'].map(combo_mean)\n",
    "\n",
    "full = full.sort_values(['product_rk', 'store_location_rk', 'period_start_dt']).reset_index(drop=True)\n",
    "full = add_group_lags(full, ['product_rk', 'store_location_rk'], 'demand', [1, 2, 3, 4, 7, 14, 21, 28])\n",
    "full = add_group_rolls(full, ['product_rk', 'store_location_rk'], 'demand', [2, 4, 6, 8, 12, 26])\n",
    "full['demand_ewm_0_3'] = (\n",
    "    full.groupby(['product_rk', 'store_location_rk'], group_keys=False)['demand']\n",
    "    .apply(lambda s: s.shift(1).ewm(alpha=0.3, adjust=False).mean())\n",
    ")\n",
    "full['demand_ewm_0_8'] = (\n",
    "    full.groupby(['product_rk', 'store_location_rk'], group_keys=False)['demand']\n",
    "    .apply(lambda s: s.shift(1).ewm(alpha=0.8, adjust=False).mean())\n",
    ")\n",
    "full['days_since_first_record'] = (\n",
    "    full.groupby(['product_rk', 'store_location_rk'])['period_start_dt']\n",
    "    .transform(lambda s: (s - s.min()).dt.days)\n",
    ")\n",
    "\n",
    "float_cols = full.select_dtypes(include=['float32', 'float64']).columns\n",
    "full[float_cols] = full[float_cols].astype('float32')\n",
    "print('Feature matrix shape:', full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fda82431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_rk</th>\n",
       "      <th>store_location_rk</th>\n",
       "      <th>period_start_dt</th>\n",
       "      <th>demand</th>\n",
       "      <th>promo1_flag</th>\n",
       "      <th>promo2_flag</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_after_disc</th>\n",
       "      <th>num_consultant</th>\n",
       "      <th>autorization_flag</th>\n",
       "      <th>dataset</th>\n",
       "      <th>store_location_lvl_rk4</th>\n",
       "      <th>store_location_lvl_rk3</th>\n",
       "      <th>store_location_lvl_rk2</th>\n",
       "      <th>store_location_lvl_rk1</th>\n",
       "      <th>store_location_adk_hashing</th>\n",
       "      <th>store_location_attrib1_hashing</th>\n",
       "      <th>store_location_attrib2_hashing</th>\n",
       "      <th>store_location_attrib3_hashing</th>\n",
       "      <th>store_location_attrib4_hashing</th>\n",
       "      <th>store_location_attrib5_hashing</th>\n",
       "      <th>store_location_attrib6_hashing</th>\n",
       "      <th>store_location_attrib7_hashing</th>\n",
       "      <th>store_location_attrib8_hashing</th>\n",
       "      <th>store_location_attrib9_hashing</th>\n",
       "      <th>store_location_attrib10_hashing</th>\n",
       "      <th>store_location_attrib11_hashing</th>\n",
       "      <th>store_location_attrib12_hashing</th>\n",
       "      <th>store_location_attrib13_hashing</th>\n",
       "      <th>store_location_attrib14_hashing</th>\n",
       "      <th>store_location_attrib15_hashing</th>\n",
       "      <th>store_location_attrib16_hashing</th>\n",
       "      <th>store_location_attrib17_hashing</th>\n",
       "      <th>store_location_attrib18_hashing</th>\n",
       "      <th>store_location_attrib19_hashing</th>\n",
       "      <th>store_location_attrib20_hashing</th>\n",
       "      <th>store_location_attrib21_hashing</th>\n",
       "      <th>store_open_dttm_year</th>\n",
       "      <th>store_open_dttm_month</th>\n",
       "      <th>store_open_dttm_isnull</th>\n",
       "      <th>store_closure_dttm_year</th>\n",
       "      <th>store_closure_dttm_month</th>\n",
       "      <th>store_closure_dttm_isnull</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>discount_pct</th>\n",
       "      <th>price_ratio</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekofmonth</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>store_mean_demand</th>\n",
       "      <th>product_mean_demand</th>\n",
       "      <th>product_store_mean_demand</th>\n",
       "      <th>demand_lag_1</th>\n",
       "      <th>demand_lag_2</th>\n",
       "      <th>demand_lag_3</th>\n",
       "      <th>demand_lag_4</th>\n",
       "      <th>demand_lag_7</th>\n",
       "      <th>demand_lag_14</th>\n",
       "      <th>demand_lag_21</th>\n",
       "      <th>demand_lag_28</th>\n",
       "      <th>demand_roll_mean_2</th>\n",
       "      <th>demand_roll_mean_4</th>\n",
       "      <th>demand_roll_mean_6</th>\n",
       "      <th>demand_roll_mean_8</th>\n",
       "      <th>demand_roll_mean_12</th>\n",
       "      <th>demand_roll_mean_26</th>\n",
       "      <th>demand_ewm_0_3</th>\n",
       "      <th>demand_ewm_0_8</th>\n",
       "      <th>days_since_first_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40369</td>\n",
       "      <td>309</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>55.666668</td>\n",
       "      <td>17.451267</td>\n",
       "      <td>68.666664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8455</th>\n",
       "      <td>12076</td>\n",
       "      <td>40370</td>\n",
       "      <td>562</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>12.556425</td>\n",
       "      <td>23.344059</td>\n",
       "      <td>22.978071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28371</th>\n",
       "      <td>17655</td>\n",
       "      <td>46272</td>\n",
       "      <td>862</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>14.818611</td>\n",
       "      <td>6.912034</td>\n",
       "      <td>10.750141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8290</th>\n",
       "      <td>11149</td>\n",
       "      <td>40370</td>\n",
       "      <td>557</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>16.261204</td>\n",
       "      <td>23.344059</td>\n",
       "      <td>32.703659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28536</th>\n",
       "      <td>18584</td>\n",
       "      <td>46272</td>\n",
       "      <td>866</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>10.671259</td>\n",
       "      <td>6.912034</td>\n",
       "      <td>7.851871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  product_rk  store_location_rk period_start_dt  demand  \\\n",
       "0          0       40369                309      2016-12-19    29.0   \n",
       "8455   12076       40370                562      2016-12-19    34.0   \n",
       "28371  17655       46272                862      2016-12-19    17.0   \n",
       "8290   11149       40370                557      2016-12-19    54.0   \n",
       "28536  18584       46272                866      2016-12-19    26.0   \n",
       "\n",
       "       promo1_flag  promo2_flag  price_regular  price_after_disc  \\\n",
       "0              0.0          0.0          500.0             500.0   \n",
       "8455           0.0          0.0         1000.0            1000.0   \n",
       "28371          0.0          0.0          223.0             223.0   \n",
       "8290           0.0          0.0         1000.0            1000.0   \n",
       "28536          0.0          0.0          223.0             223.0   \n",
       "\n",
       "       num_consultant  autorization_flag dataset  store_location_lvl_rk4  \\\n",
       "0                 0.0                0.0   train                     203   \n",
       "8455              0.0                0.0   train                      36   \n",
       "28371             0.0                0.0   train                      54   \n",
       "8290              0.0                0.0   train                      54   \n",
       "28536             0.0                0.0   train                     219   \n",
       "\n",
       "       store_location_lvl_rk3  store_location_lvl_rk2  store_location_lvl_rk1  \\\n",
       "0                         203                      10                       1   \n",
       "8455                       36                      10                       1   \n",
       "28371                      54                      10                       1   \n",
       "8290                       54                      10                       1   \n",
       "28536                     219                      10                       1   \n",
       "\n",
       "       store_location_adk_hashing  store_location_attrib1_hashing  \\\n",
       "0                               0                               1   \n",
       "8455                            0                               1   \n",
       "28371                           0                               1   \n",
       "8290                            0                               1   \n",
       "28536                           0                               1   \n",
       "\n",
       "       store_location_attrib2_hashing  store_location_attrib3_hashing  \\\n",
       "0                                   0                              16   \n",
       "8455                                0                              19   \n",
       "28371                               0                               8   \n",
       "8290                                2                              16   \n",
       "28536                               0                               8   \n",
       "\n",
       "       store_location_attrib4_hashing  store_location_attrib5_hashing  \\\n",
       "0                                  13                               6   \n",
       "8455                                1                               6   \n",
       "28371                               1                               6   \n",
       "8290                                1                               6   \n",
       "28536                              55                               6   \n",
       "\n",
       "       store_location_attrib6_hashing  store_location_attrib7_hashing  \\\n",
       "0                                   1                              12   \n",
       "8455                                1                              12   \n",
       "28371                               1                              12   \n",
       "8290                                1                              12   \n",
       "28536                               1                              12   \n",
       "\n",
       "       store_location_attrib8_hashing  store_location_attrib9_hashing  \\\n",
       "0                                  80                               1   \n",
       "8455                                9                               0   \n",
       "28371                              55                               0   \n",
       "8290                               55                               0   \n",
       "28536                              55                               0   \n",
       "\n",
       "       store_location_attrib10_hashing  store_location_attrib11_hashing  \\\n",
       "0                                    3                                2   \n",
       "8455                                 1                                1   \n",
       "28371                                1                                1   \n",
       "8290                                 1                                1   \n",
       "28536                                1                                1   \n",
       "\n",
       "       store_location_attrib12_hashing  store_location_attrib13_hashing  \\\n",
       "0                                    2                                3   \n",
       "8455                                 1                                0   \n",
       "28371                                1                                0   \n",
       "8290                                 1                                0   \n",
       "28536                                1                                0   \n",
       "\n",
       "       store_location_attrib14_hashing  store_location_attrib15_hashing  \\\n",
       "0                                    2                                2   \n",
       "8455                                 2                                0   \n",
       "28371                                2                                2   \n",
       "8290                                 2                                2   \n",
       "28536                                2                                2   \n",
       "\n",
       "       store_location_attrib16_hashing  store_location_attrib17_hashing  \\\n",
       "0                                    0                                0   \n",
       "8455                                 0                                0   \n",
       "28371                                0                                0   \n",
       "8290                                 0                                0   \n",
       "28536                                0                                0   \n",
       "\n",
       "       store_location_attrib18_hashing  store_location_attrib19_hashing  \\\n",
       "0                                    0                                0   \n",
       "8455                                 0                                0   \n",
       "28371                                0                                0   \n",
       "8290                                 0                                0   \n",
       "28536                                0                                0   \n",
       "\n",
       "       store_location_attrib20_hashing  store_location_attrib21_hashing  \\\n",
       "0                                    0                                0   \n",
       "8455                                 0                                0   \n",
       "28371                                0                                0   \n",
       "8290                                 0                                0   \n",
       "28536                                0                                0   \n",
       "\n",
       "       store_open_dttm_year  store_open_dttm_month  store_open_dttm_isnull  \\\n",
       "0                      2018                      3                       0   \n",
       "8455                   2018                      3                       0   \n",
       "28371                  2018                      3                       0   \n",
       "8290                   2018                      3                       0   \n",
       "28536                  2018                      3                       0   \n",
       "\n",
       "       store_closure_dttm_year  store_closure_dttm_month  \\\n",
       "0                          NaN                       NaN   \n",
       "8455                       NaN                       NaN   \n",
       "28371                      NaN                       NaN   \n",
       "8290                       NaN                       NaN   \n",
       "28536                      NaN                       NaN   \n",
       "\n",
       "       store_closure_dttm_isnull  discount_amount  discount_pct  price_ratio  \\\n",
       "0                              1              0.0           0.0          1.0   \n",
       "8455                           1              0.0           0.0          1.0   \n",
       "28371                          1              0.0           0.0          1.0   \n",
       "8290                           1              0.0           0.0          1.0   \n",
       "28536                          1              0.0           0.0          1.0   \n",
       "\n",
       "       weekofyear  month  quarter  dayofweek  weekofmonth  is_month_start  \\\n",
       "0            51.0   12.0      4.0        0.0          2.0               0   \n",
       "8455         51.0   12.0      4.0        0.0          2.0               0   \n",
       "28371        51.0   12.0      4.0        0.0          2.0               0   \n",
       "8290         51.0   12.0      4.0        0.0          2.0               0   \n",
       "28536        51.0   12.0      4.0        0.0          2.0               0   \n",
       "\n",
       "       is_month_end  dayofyear  store_mean_demand  product_mean_demand  \\\n",
       "0                 0      354.0          55.666668            17.451267   \n",
       "8455              0      354.0          12.556425            23.344059   \n",
       "28371             0      354.0          14.818611             6.912034   \n",
       "8290              0      354.0          16.261204            23.344059   \n",
       "28536             0      354.0          10.671259             6.912034   \n",
       "\n",
       "       product_store_mean_demand  demand_lag_1  demand_lag_2  demand_lag_3  \\\n",
       "0                      68.666664           NaN           NaN           NaN   \n",
       "8455                   22.978071           NaN           NaN           NaN   \n",
       "28371                  10.750141           NaN           NaN           NaN   \n",
       "8290                   32.703659           NaN           NaN           NaN   \n",
       "28536                   7.851871           NaN           NaN           NaN   \n",
       "\n",
       "       demand_lag_4  demand_lag_7  demand_lag_14  demand_lag_21  \\\n",
       "0               NaN           NaN            NaN            NaN   \n",
       "8455            NaN           NaN            NaN            NaN   \n",
       "28371           NaN           NaN            NaN            NaN   \n",
       "8290            NaN           NaN            NaN            NaN   \n",
       "28536           NaN           NaN            NaN            NaN   \n",
       "\n",
       "       demand_lag_28  demand_roll_mean_2  demand_roll_mean_4  \\\n",
       "0                NaN                 NaN                 NaN   \n",
       "8455             NaN                 NaN                 NaN   \n",
       "28371            NaN                 NaN                 NaN   \n",
       "8290             NaN                 NaN                 NaN   \n",
       "28536            NaN                 NaN                 NaN   \n",
       "\n",
       "       demand_roll_mean_6  demand_roll_mean_8  demand_roll_mean_12  \\\n",
       "0                     NaN                 NaN                  NaN   \n",
       "8455                  NaN                 NaN                  NaN   \n",
       "28371                 NaN                 NaN                  NaN   \n",
       "8290                  NaN                 NaN                  NaN   \n",
       "28536                 NaN                 NaN                  NaN   \n",
       "\n",
       "       demand_roll_mean_26  demand_ewm_0_3  demand_ewm_0_8  \\\n",
       "0                      NaN             NaN             NaN   \n",
       "8455                   NaN             NaN             NaN   \n",
       "28371                  NaN             NaN             NaN   \n",
       "8290                   NaN             NaN             NaN   \n",
       "28536                  NaN             NaN             NaN   \n",
       "\n",
       "       days_since_first_record  \n",
       "0                          0.0  \n",
       "8455                       0.0  \n",
       "28371                      0.0  \n",
       "8290                       0.0  \n",
       "28536                      0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "full.sort_values('period_start_dt').head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf8f2955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train span: 2016-12-19 00:00:00 -> 2019-11-25 00:00:00\n",
      "Valid span: 2019-12-02 00:00:00 -> 2019-12-30 00:00:00\n",
      "Feature count: 71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_processed = full[(full['dataset'] == 'train') & (full['demand'].notna())].copy()\n",
    "test_processed = full[full['dataset'] == 'test'].copy()\n",
    "\n",
    "feature_drop = {'dataset', 'demand', 'period_start_dt'}\n",
    "if 'id' in feature_drop:\n",
    "    feature_drop.remove('id')\n",
    "feature_cols = [c for c in train_processed.columns if c not in feature_drop.union({'id'})]\n",
    "\n",
    "for df in (train_processed, test_processed):\n",
    "    df[feature_cols] = df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "for col in feature_cols:\n",
    "    median_value = train_processed[col].median()\n",
    "    train_processed[col] = train_processed[col].fillna(median_value)\n",
    "    test_processed[col] = test_processed[col].fillna(median_value)\n",
    "\n",
    "train_processed[feature_cols] = train_processed[feature_cols].fillna(0)\n",
    "test_processed[feature_cols] = test_processed[feature_cols].fillna(0)\n",
    "\n",
    "train_processed = train_processed.sort_values('period_start_dt')\n",
    "max_date = train_processed['period_start_dt'].max()\n",
    "val_start = max_date - pd.Timedelta(days=28)\n",
    "train_mask = train_processed['period_start_dt'] < val_start\n",
    "valid_mask = ~train_mask\n",
    "\n",
    "train_data = train_processed.loc[train_mask]\n",
    "valid_data = train_processed.loc[valid_mask]\n",
    "\n",
    "print('Train span:', train_data['period_start_dt'].min(), '->', train_data['period_start_dt'].max())\n",
    "print('Valid span:', valid_data['period_start_dt'].min(), '->', valid_data['period_start_dt'].max())\n",
    "print('Feature count:', len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6353042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6000\n",
      "[LightGBM] [Info] Number of data points in the train set: 34144, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 6.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttrain's l1: 4.18518\tvalid's l1: 13.8031\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's l1: 9.99981\tvalid's l1: 6.08988\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 29\u001b[0m\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     20\u001b[0m     params,\n\u001b[1;32m     21\u001b[0m     lgb_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[lgb\u001b[38;5;241m.\u001b[39mearly_stopping(\u001b[38;5;241m200\u001b[39m), lgb\u001b[38;5;241m.\u001b[39mlog_evaluation(\u001b[38;5;241m200\u001b[39m)],\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m valid_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(valid_data[feature_cols], num_iteration\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbest_iteration)\n\u001b[0;32m---> 29\u001b[0m val_mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand\u001b[39m\u001b[38;5;124m'\u001b[39m], valid_pred)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_regression.py:277\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m0.85...\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[1;32m    276\u001b[0m _, y_true, y_pred, sample_weight, multioutput \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 277\u001b[0m     _check_reg_targets_with_floating_dtype(\n\u001b[1;32m    278\u001b[0m         y_true, y_pred, sample_weight, multioutput, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    282\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    284\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m _average(\n\u001b[1;32m    285\u001b[0m     xp\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[1;32m    286\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_regression.py:198\u001b[0m, in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mregression task.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dtype_name \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m--> 198\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    199\u001b[0m     y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39mdtype_name, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_regression.py:105\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    104\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    106\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1108\u001b[0m         array,\n\u001b[1;32m   1109\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1110\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1111\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mensure_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1112\u001b[0m     )\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    121\u001b[0m     X,\n\u001b[1;32m    122\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    123\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    124\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    125\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    126\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    127\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "\n",
    "lgb_train = lgb.Dataset(train_data[feature_cols], label=train_data['demand'])\n",
    "lgb_valid = lgb.Dataset(valid_data[feature_cols], label=valid_data['demand'])\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 256,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'lambda_l1': 0.01,\n",
    "    'lambda_l2': 1.0,\n",
    "    'seed': SEED,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train', 'valid'],\n",
    "    num_boost_round=5000,\n",
    "    callbacks=[lgb.early_stopping(200), lgb.log_evaluation(200)],\n",
    ")\n",
    "\n",
    "valid_pred = model.predict(valid_data[feature_cols], num_iteration=model.best_iteration)\n",
    "val_mae = mean_absolute_error(valid_data['demand'], valid_pred)\n",
    "print(f'Validation MAE: {val_mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a79a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fi = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance_gain': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance_gain', ascending=False)\n",
    "fi.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_pred = model.predict(test_processed[feature_cols], num_iteration=model.best_iteration)\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_processed['id'].astype(int),\n",
    "    'predicted': np.clip(test_pred, 0, None)\n",
    "})\n",
    "submission.to_csv('bebebe.csv', index=False)\n",
    "print('Saved submission.csv with shape:', submission.shape)\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anaconda-base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
