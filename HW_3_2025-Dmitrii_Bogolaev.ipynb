{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Demand Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 2025\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = np.clip((np.abs(y_true) + np.abs(y_pred)) / 2.0, 1e-9, None)\n",
    "    return np.mean(numerator / denominator) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (35329, 9)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv('train.csv')\n",
    "test_ids_df = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "all_data['period_start_dt'] = pd.to_datetime(all_data['period_start_dt'], format='%Y-%m-%d')\n",
    "all_data.rename(columns={'Unnamed: 0': 'id'}, inplace=True)\n",
    "\n",
    "del all_data['PROMO2_FLAG']\n",
    "del all_data['NUM_CONSULTANT']\n",
    "all_data['PROMO1_FLAG'] = all_data['PROMO1_FLAG'].fillna(0)\n",
    "all_data['AUTORIZATION_FLAG'] = all_data['AUTORIZATION_FLAG'].fillna(0)\n",
    "all_data['PRICE_REGULAR'] = all_data['PRICE_REGULAR'].fillna(all_data['PRICE_REGULAR'].median())\n",
    "all_data['PRICE_AFTER_DISC'] = all_data['PRICE_AFTER_DISC'].fillna(all_data['PRICE_AFTER_DISC'].median())\n",
    "all_data = all_data[all_data['store_location_rk'] != 309].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['month'] = all_data['period_start_dt'].dt.month\n",
    "all_data['dayofweek'] = all_data['period_start_dt'].dt.dayofweek\n",
    "all_data['dayofyear'] = all_data['period_start_dt'].dt.dayofyear\n",
    "all_data['weekofyear'] = all_data['period_start_dt'].dt.isocalendar().week.astype(int)\n",
    "all_data['quarter'] = all_data['period_start_dt'].dt.quarter\n",
    "all_data['is_weekend'] = (all_data['dayofweek'] >= 5).astype(int)\n",
    "all_data['is_month_start'] = all_data['period_start_dt'].dt.is_month_start.astype(int)\n",
    "all_data['is_month_end'] = all_data['period_start_dt'].dt.is_month_end.astype(int)\n",
    "\n",
    "all_data['discount'] = (all_data['PRICE_REGULAR'] - all_data['PRICE_AFTER_DISC']).clip(lower=0)\n",
    "all_data['discount_pct'] = (all_data['discount'] / all_data['PRICE_REGULAR'].replace(0, np.nan)).fillna(0)\n",
    "\n",
    "all_data['log_price_regular'] = np.log1p(all_data['PRICE_REGULAR'])\n",
    "all_data['log_price_after_disc'] = np.log1p(all_data['PRICE_AFTER_DISC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.sort_values(['product_rk', 'store_location_rk', 'period_start_dt']).reset_index(drop=True)\n",
    "\n",
    "for lag in [7, 14, 21, 28]:\n",
    "    all_data[f'demand_lag_{lag}'] = all_data.groupby(['product_rk', 'store_location_rk'])['demand'].shift(lag)\n",
    "\n",
    "for window in [7, 14, 28]:\n",
    "    all_data[f'demand_roll_mean_{window}'] = all_data.groupby(['product_rk', 'store_location_rk'])['demand'].transform(\n",
    "        lambda x: x.shift(1).rolling(window=window, min_periods=1).mean()\n",
    "    )\n",
    "    all_data[f'demand_roll_std_{window}'] = all_data.groupby(['product_rk', 'store_location_rk'])['demand'].transform(\n",
    "        lambda x: x.shift(1).rolling(window=window, min_periods=1).std()\n",
    "    )\n",
    "\n",
    "for alpha in [0.5, 0.7]:\n",
    "    all_data[f'demand_ewm_{alpha}'] = all_data.groupby(['product_rk', 'store_location_rk'])['demand'].transform(\n",
    "        lambda x: x.shift(1).ewm(alpha=alpha, min_periods=1).mean()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_only = all_data[all_data['demand'].notna()].copy()\n",
    "\n",
    "product_stats = train_only.groupby('product_rk')['demand'].agg(['mean', 'std', 'median']).reset_index()\n",
    "product_stats.columns = ['product_rk', 'product_mean', 'product_std', 'product_median']\n",
    "all_data = all_data.merge(product_stats, on='product_rk', how='left')\n",
    "\n",
    "store_stats = train_only.groupby('store_location_rk')['demand'].agg(['mean', 'std']).reset_index()\n",
    "store_stats.columns = ['store_location_rk', 'store_mean', 'store_std']\n",
    "all_data = all_data.merge(store_stats, on='store_location_rk', how='left')\n",
    "\n",
    "product_month_stats = train_only.groupby(['product_rk', 'month'])['demand'].mean().reset_index()\n",
    "product_month_stats.columns = ['product_rk', 'month', 'product_month_mean']\n",
    "all_data = all_data.merge(product_month_stats, on=['product_rk', 'month'], how='left')\n",
    "\n",
    "product_dow_stats = train_only.groupby(['product_rk', 'dayofweek'])['demand'].mean().reset_index()\n",
    "product_dow_stats.columns = ['product_rk', 'dayofweek', 'product_dow_mean']\n",
    "all_data = all_data.merge(product_dow_stats, on=['product_rk', 'dayofweek'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['promo_x_discount'] = all_data['PROMO1_FLAG'] * all_data['discount_pct']\n",
    "all_data['auth_x_discount'] = all_data['AUTORIZATION_FLAG'] * all_data['discount_pct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [35, 42, 49, 56]:\n",
    "    all_data[f'demand_lag_{lag}'] = all_data.groupby(['product_rk', 'store_location_rk'])['demand'].shift(lag)\n",
    "\n",
    "all_data['demand_expanding_mean'] = all_data.groupby(['product_rk', 'store_location_rk'])['demand'].transform(\n",
    "    lambda x: x.shift(1).expanding(min_periods=1).mean()\n",
    ")\n",
    "all_data['demand_expanding_std'] = all_data.groupby(['product_rk', 'store_location_rk'])['demand'].transform(\n",
    "    lambda x: x.shift(1).expanding(min_periods=1).std()\n",
    ")\n",
    "\n",
    "for window in [7, 14, 28]:\n",
    "    mean_col = f'demand_roll_mean_{window}'\n",
    "    std_col = f'demand_roll_std_{window}'\n",
    "    all_data[f'demand_cv_{window}'] = all_data[std_col] / (all_data[mean_col] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['price_ratio'] = all_data['PRICE_AFTER_DISC'] / (all_data['PRICE_REGULAR'] + 1)\n",
    "all_data['price_change_rate'] = all_data.groupby(['product_rk', 'store_location_rk'])['PRICE_REGULAR'].pct_change()\n",
    "\n",
    "product_store_mean = all_data.groupby(['product_rk', 'store_location_rk'])['demand'].transform('mean')\n",
    "all_data['product_store_demand_mean'] = product_store_mean\n",
    "\n",
    "all_data['week_year'] = all_data['weekofyear'] + all_data['period_start_dt'].dt.year * 100\n",
    "\n",
    "all_data['is_holiday_season'] = ((all_data['month'] == 11) | (all_data['month'] == 12)).astype(int)\n",
    "\n",
    "all_data['is_year_start'] = (all_data['weekofyear'] <= 2).astype(int)\n",
    "all_data['is_year_end'] = (all_data['weekofyear'] >= 50).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_data[all_data['demand'].notna()].copy()\n",
    "test_df = all_data[all_data['demand'].isna()].copy()\n",
    "\n",
    "train_df = train_df.sort_values('period_start_dt')\n",
    "split_date = train_df['period_start_dt'].quantile(0.85)\n",
    "\n",
    "X_train = train_df[train_df['period_start_dt'] < split_date].copy()\n",
    "X_val = train_df[train_df['period_start_dt'] >= split_date].copy()\n",
    "\n",
    "feature_cols = [c for c in all_data.columns if c not in \n",
    "                ['id', 'period_start_dt', 'demand', 'Unnamed: 0']]\n",
    "\n",
    "for col in feature_cols:\n",
    "    X_train[col] = X_train[col].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    X_val[col] = X_val[col].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    test_df[col] = test_df[col].fillna(0).replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train[feature_cols], label=X_train['demand'])\n",
    "dval = xgb.DMatrix(X_val[feature_cols], label=X_val['demand'])\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.85,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 0.05,\n",
    "    'reg_alpha': 0.05,\n",
    "    'reg_lambda': 1.5,\n",
    "    'tree_method': 'hist',\n",
    "    'seed': SEED,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "evals = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=3000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=150,\n",
    "    verbose_eval=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train[feature_cols], label=X_train['demand'])\n",
    "lgb_val = lgb.Dataset(X_val[feature_cols], label=X_val['demand'], reference=lgb_train)\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 63,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 20,\n",
    "    'lambda_l1': 0.05,\n",
    "    'lambda_l2': 1.5,\n",
    "    'seed': SEED,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=3000,\n",
    "    valid_sets=[lgb_train, lgb_val],\n",
    "    valid_names=['train', 'val'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=150),\n",
    "        lgb.log_evaluation(period=200)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cb_model = CatBoostRegressor(\n",
    "    iterations=3000,\n",
    "    learning_rate=0.03,\n",
    "    depth=7,\n",
    "    l2_leaf_reg=1.5,\n",
    "    random_strength=0.5,\n",
    "    bagging_temperature=0.2,\n",
    "    od_type='Iter',\n",
    "    od_wait=150,\n",
    "    random_seed=SEED,\n",
    "    verbose=200,\n",
    "    loss_function='MAE'\n",
    ")\n",
    "\n",
    "cb_model.fit(\n",
    "    X_train[feature_cols], \n",
    "    X_train['demand'],\n",
    "    eval_set=(X_val[feature_cols], X_val['demand']),\n",
    "    use_best_model=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_val_pred = xgb_model.predict(dval, iteration_range=(0, xgb_model.best_iteration + 1))\n",
    "xgb_val_pred = np.clip(xgb_val_pred, 0, None)\n",
    "\n",
    "lgb_val_pred = lgb_model.predict(X_val[feature_cols], num_iteration=lgb_model.best_iteration)\n",
    "lgb_val_pred = np.clip(lgb_val_pred, 0, None)\n",
    "\n",
    "cb_val_pred = cb_model.predict(X_val[feature_cols])\n",
    "cb_val_pred = np.clip(cb_val_pred, 0, None)\n",
    "\n",
    "xgb_smape = smape(X_val['demand'].values, xgb_val_pred)\n",
    "lgb_smape = smape(X_val['demand'].values, lgb_val_pred)\n",
    "cb_smape = smape(X_val['demand'].values, cb_val_pred)\n",
    "\n",
    "weights = np.array([1/xgb_smape, 1/lgb_smape, 1/cb_smape])\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "ensemble_val_pred = (weights[0] * xgb_val_pred + \n",
    "                     weights[1] * lgb_val_pred + \n",
    "                     weights[2] * cb_val_pred)\n",
    "ensemble_val_pred = np.clip(ensemble_val_pred, 0, None)\n",
    "\n",
    "ensemble_smape = smape(X_val['demand'].values, ensemble_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test_df[feature_cols])\n",
    "xgb_test_pred = xgb_model.predict(dtest, iteration_range=(0, xgb_model.best_iteration + 1))\n",
    "xgb_test_pred = np.clip(xgb_test_pred, 0, None)\n",
    "\n",
    "lgb_test_pred = lgb_model.predict(test_df[feature_cols], num_iteration=lgb_model.best_iteration)\n",
    "lgb_test_pred = np.clip(lgb_test_pred, 0, None)\n",
    "\n",
    "cb_test_pred = cb_model.predict(test_df[feature_cols])\n",
    "cb_test_pred = np.clip(cb_test_pred, 0, None)\n",
    "\n",
    "ensemble_test_pred = (weights[0] * xgb_test_pred + \n",
    "                      weights[1] * lgb_test_pred + \n",
    "                      weights[2] * cb_test_pred)\n",
    "ensemble_test_pred = np.clip(ensemble_test_pred, 0, None)\n",
    "\n",
    "# Create submission\n",
    "pred_df = pd.DataFrame({'id': test_df['id'].astype(int), 'predicted': ensemble_test_pred})\n",
    "\n",
    "test_ids_set = set(test_ids_df['id'].values)\n",
    "submission = sample_submission[['id']].merge(pred_df[pred_df['id'].isin(test_ids_set)], on='id', how='left')\n",
    "\n",
    "# Fill missing values with product means\n",
    "product_means = train_df.groupby('product_rk')['demand'].mean().to_dict()\n",
    "for idx, row in submission.iterrows():\n",
    "    if pd.isna(row['predicted']):\n",
    "        matching = test_df[test_df['id'] == row['id']]\n",
    "        if len(matching) > 0:\n",
    "            prod_rk = matching.iloc[0]['product_rk']\n",
    "            submission.at[idx, 'predicted'] = product_means.get(prod_rk, train_df['demand'].mean())\n",
    "\n",
    "submission['predicted'] = submission['predicted'].fillna(train_df['demand'].mean())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission_ensemble.csv', index=False)\n",
    "print(f\"âœ… Submission saved to 'submission_ensemble.csv'\")\n",
    "print(f\"ðŸ“Š Submission shape: {submission.shape}\")\n",
    "print(f\"ðŸ“Š Sample predictions:\\n{submission.head(10)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
